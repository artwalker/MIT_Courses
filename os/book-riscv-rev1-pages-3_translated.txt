Chapter 2 Operating system organization A key requirement for an operating system is to support several activities at once.
For example, using the system call interface described in Chapter 1 a process can start new processes with fork.
The operating system must time-share the resources of the computer among these processes.
For example, even if there are more processes than there are hardware CPUs, the operating system must ensure that all of the processes get a chance to execute.
The operating system must also arrange for isolation between the processes.
That is, if one process has a bug and malfunctions, it shouldn’t affect processes that don’t depend on the buggy process.
Complete isolation, however, is too strong, since it should be possible for processes to intentionally interact; pipelines are an example.
Thus an operating system must fulﬁll three requirements: multiplexing, isolation, and interaction.
第2章 操作系统组织
操作系统的一个关键要求是同时支持多个活动。
例如，使用第1章中描述的系统调用接口，一个进程可以使用fork启动新的进程。
操作系统必须在这些进程之间进行时间共享计算机资源。
例如，即使进程数量超过硬件CPU数量，操作系统也必须确保所有进程都有机会执行。
操作系统还必须为进程之间提供隔离。
也就是说，如果一个进程有错误并发生故障，它不应该影响不依赖于有错误进程的进程。
然而，完全隔离是过于严格的，因为进程应该有意地进行交互；管道就是一个例子。
因此，操作系统必须满足三个要求：多路复用、隔离和交互。

 This chapter provides an overview of how operating systems are organized to achieve these three requirements.
It turns out there are many ways to do so, but this text focuses on mainstream designs centered around a monolithic kernel, which is used by many Unix operating systems.
This chapter also provides an overview of an xv6 process, which is the unit of isolation in xv6, and the creation of the ﬁrst process when xv6 starts.
Xv6 runs on a multi-core1 RISC-V microprocessor, and much of its low-level functionality (for example, its process implementation) is speciﬁc to RISC-V.
RISC-V is a 64-bit CPU, and xv6 is written in “LP64” C, which means long (L) and pointers (P) in the C programming language are 64 bits, but int is 32-bit.
This book assumes the reader has done a bit of machine-level programming on some architecture, and will introduce RISC-V-speciﬁc ideas as they come up.
A useful reference for RISC-V is “The RISC-V Reader: An Open Architecture Atlas” [12].
本章概述了操作系统如何组织以实现这三个要求。
事实证明，有很多种方法可以做到这一点，但本文重点介绍了围绕着单内核的主流设计，这种设计被许多Unix操作系统使用。
本章还概述了xv6进程，这是xv6中的隔离单元，并介绍了xv6启动时第一个进程的创建过程。
Xv6运行在多核RISC-V微处理器上，它的许多低级功能（例如进程实现）是特定于RISC-V的。
RISC-V是一种64位CPU，而xv6是用“LP64” C语言编写的，这意味着C语言中的长（L）和指针（P）都是64位，但int是32位。
本书假设读者在某种体系结构上已经进行了一些机器级编程，并将在需要时介绍RISC-V特定的思想。
关于RISC-V的一个有用参考资料是《RISC-V Reader: An Open Architecture Atlas》[12]。

 The user-level ISA [2] and the privileged architecture [1] are the ofﬁcial speciﬁcations.
The CPU in a complete computer is surrounded by support hardware, much of it in the form of I/O interfaces.
Xv6 is written for the support hardware simulated by qemu’s “-machine virt” option.
This includes RAM, a ROM containing boot code, a serial connection to the user’s key- board/screen, and a disk for storage.
1By “multi-core” this text means multiple CPUs that share memory but execute in parallel, each with its own set of registers.
This text sometimes uses the term multiprocessor as a synonym for multi-core, though multiprocessor can also refer more speciﬁcally to a computer with several distinct processor chips.
21 2.1 Abstracting physical resources The ﬁrst question one might ask when encountering an operating system is why have it at all? That is, one could implement the system calls in Figure 1.2 as a library, with which applications link.
用户级ISA [2]和特权架构[1]是官方规范。
完整计算机中的CPU被支持硬件所包围，其中大部分以I/O接口的形式存在。
Xv6是为qemu的“-machine virt”选项模拟的支持硬件编写的。
这包括RAM、包含引导代码的ROM、与用户的键盘/屏幕连接的串行连接以及用于存储的磁盘。
1在本文中，“多核”指的是共享内存但并行执行的多个CPU，每个CPU都有自己的一组寄存器。
本文有时将多处理器作为多核的同义词使用，尽管多处理器也可以更具体地指多个不同的处理器芯片的计算机。
21 2.1抽象物理资源当遇到操作系统时，人们可能会问为什么需要它？也就是说，可以将图1.2中的系统调用实现为一个库，应用程序与之链接。

 In this plan, each application could even have its own library tailored to its needs.
Applications could directly interact with hardware resources and use those resources in the best way for the application (e.g., to achieve high or predictable performance).
Some operating systems for embedded devices or real-time systems are organized in this way.
The downside of this library approach is that, if there is more than one application running, the applications must be well-behaved.
For example, each application must periodically give up the CPU so that other applications can run.
Such a cooperative time-sharing scheme may be OK if all applications trust each other and have no bugs.
It’s more typical for applications to not trust each other, and to have bugs, so one often wants stronger isolation than a cooperative scheme provides.
To achieve strong isolation it’s helpful to forbid applications from directly accessing sensitive hardware resources, and instead to abstract the resources into services.
在这个计划中，每个应用程序甚至可以拥有自己的专门库以满足其需求。
应用程序可以直接与硬件资源进行交互，并以最佳方式利用这些资源以实现高性能或可预测性能。
一些嵌入式设备或实时系统的操作系统就是以这种方式组织的。
这种库方法的缺点是，如果有多个应用程序在运行，这些应用程序必须表现良好。
例如，每个应用程序必须定期放弃CPU，以便其他应用程序可以运行。
如果所有应用程序都互相信任且没有错误，这种合作的时间共享方案可能是可以接受的。
但更常见的情况是应用程序彼此不信任且存在错误，因此人们通常希望获得比合作方案提供的更强的隔离性。
为了实现强隔离，禁止应用程序直接访问敏感的硬件资源，并将这些资源抽象为服务是有帮助的。

 For example, Unix applica- tions interact with storage only through the ﬁle system’s open, read, write, and close system calls, instead of reading and writing the disk directly.
This provides the application with the con- venience of pathnames, and it allows the operating system (as the implementer of the interface) to manage the disk.
Even if isolation is not a concern, programs that interact intentionally (or just wish to keep out of each other’s way) are likely to ﬁnd a ﬁle system a more convenient abstraction than direct use of the disk.
Similarly, Unix transparently switches hardware CPUs among processes, saving and restor- ing register state as necessary, so that applications don’t have to be aware of time sharing.
This transparency allows the operating system to share CPUs even if some applications are in inﬁnite loops.
As another example, Unix processes use exec to build up their memory image, instead of directly interacting with physical memory.
例如，Unix应用程序只通过文件系统的打开、读取、写入和关闭系统调用与存储交互，而不是直接读写磁盘。
这为应用程序提供了路径名的便利，并允许操作系统（作为接口的实现者）管理磁盘。
即使隔离不是一个问题，有意交互（或只是希望彼此保持距离）的程序很可能会发现文件系统比直接使用磁盘更方便。
同样，Unix会透明地在进程之间切换硬件CPU，根据需要保存和恢复寄存器状态，这样应用程序就不需要意识到时间共享。
这种透明性使操作系统能够在一些应用程序陷入无限循环的情况下共享CPU。
再举一个例子，Unix进程使用exec来构建它们的内存映像，而不是直接与物理内存交互。

 This allows the operating system to decide where to place a process in memory; if memory is tight, the operating system might even store some of a process’s data on disk.
Exec also provides users with the convenience of a ﬁle system to store executable program images.
Many forms of interaction among Unix processes occur via ﬁle descriptors.
Not only do ﬁle descriptors abstract away many details (e.g., where data in a pipe or ﬁle is stored), they are also deﬁned in a way that simpliﬁes interaction.
For example, if one application in a pipeline fails, the kernel generates an end-of-ﬁle signal for the next process in the pipeline.
The system-call interface in Figure 1.2 is carefully designed to provide both programmer con- venience and the possibility of strong isolation.
The Unix interface is not the only way to abstract resources, but it has proven to be a very good one.
2.2 User mode, supervisor mode, and system calls Strong isolation requires a hard boundary between applications and the operating system.
这使得操作系统能够决定将进程放置在内存的何处；如果内存紧张，操作系统甚至可能将进程的一些数据存储在磁盘上。
Exec还为用户提供了一个方便的文件系统来存储可执行程序映像。
Unix进程之间的许多形式的交互都是通过文件描述符进行的。
文件描述符不仅抽象了许多细节（例如，管道或文件中的数据存储在何处），而且它们的定义方式简化了交互。
例如，如果管道中的一个应用程序失败，内核会为管道中的下一个进程生成一个文件结束信号。
图1.2中的系统调用接口经过精心设计，既提供了程序员的便利性，又提供了强大的隔离性的可能性。
Unix接口并不是抽象资源的唯一方式，但它已被证明是非常好的一种方式。
2.2 用户模式、监管模式和系统调用强大的隔离性要求应用程序和操作系统之间有一个严格的边界。

 If the application makes a mistake, we don’t want the operating system to fail or other applications to 22 fail.
Instead, the operating system should be able to clean up the failed application and continue running other applications.
To achieve strong isolation, the operating system must arrange that applications cannot modify (or even read) the operating system’s data structures and instructions and that applications cannot access other processes’ memory.
CPUs provide hardware support for strong isolation.
For example, RISC-V has three modes in which the CPU can execute instructions: machine mode, supervisor mode, and user mode.
In- structions executing in machine mode have full privilege; a CPU starts in machine mode.
Machine mode is mostly intended for conﬁguring a computer.
Xv6 executes a few lines in machine mode and then changes to supervisor mode.
如果应用程序出错，我们不希望操作系统崩溃或其他应用程序失败。
相反，操作系统应该能够清理失败的应用程序并继续运行其他应用程序。
为了实现强隔离，操作系统必须安排应用程序无法修改（甚至读取）操作系统的数据结构和指令，并且应用程序无法访问其他进程的内存。
CPU提供了强隔离的硬件支持。
例如，RISC-V有三种模式可以执行指令：机器模式、监管模式和用户模式。
在机器模式下执行的指令具有完全特权；CPU在机器模式下启动。
机器模式主要用于配置计算机。
Xv6在机器模式下执行几行指令，然后切换到监管模式。

 In supervisor mode the CPU is allowed to execute privileged instructions: for example, en- abling and disabling interrupts, reading and writing the register that holds the address of a page table, etc.
If an application in user mode attempts to execute a privileged instruction, then the CPU doesn’t execute the instruction, but switches to supervisor mode so that supervisor-mode code can terminate the application, because it did something it shouldn’t be doing.
Figure 1.1 in Chapter 1 illustrates this organization.
An application can execute only user-mode instructions (e.g., adding numbers, etc.) and is said to be running in user space, while the software in supervisor mode can also execute privileged instructions and is said to be running in kernel space.
The software running in kernel space (or in supervisor mode) is called the kernel.
An application that wants to invoke a kernel function (e.g., the read system call in xv6) must transition to the kernel.
在监管模式下，CPU被允许执行特权指令，例如启用和禁用中断、读写保存页表地址的寄存器等。
如果用户模式下的应用程序尝试执行特权指令，CPU将不执行该指令，而是切换到监管模式，以便监管模式的代码可以终止应用程序，因为它做了一些不应该做的事情。
第1章的图1.1说明了这种组织结构。
应用程序只能执行用户模式指令（例如加法运算等），并且被称为运行在用户空间中，而运行在监管模式下的软件还可以执行特权指令，并且被称为运行在内核空间中。
运行在内核空间（或监管模式下）的软件称为内核。
想要调用内核函数的应用程序（例如xv6中的读取系统调用）必须切换到内核模式。

 CPUs provide a special instruction that switches the CPU from user mode to supervisor mode and enters the kernel at an entry point speciﬁed by the kernel.
(RISC-V provides the ecall instruction for this purpose.) Once the CPU has switched to supervisor mode, the kernel can then validate the arguments of the system call, decide whether the application is allowed to perform the requested operation, and then deny it or execute it.
It is important that the kernel control the entry point for transitions to supervisor mode; if the application could decide the kernel entry point, a malicious application could, for example, enter the kernel at a point where the validation of arguments is skipped.
2.3 Kernel organization A key design question is what part of the operating system should run in supervisor mode.
One possibility is that the entire operating system resides in the kernel, so that the implementations of all system calls run in supervisor mode.
This organization is called a monolithic kernel.
CPU提供了一条特殊指令，将CPU从用户模式切换到监管模式，并在内核中的入口点进入内核。
（RISC-V为此提供了ecall指令。
）一旦CPU切换到监管模式，内核就可以验证系统调用的参数，决定应用程序是否被允许执行所请求的操作，然后拒绝或执行它。
重要的是，内核控制切换到监管模式的入口点；如果应用程序可以决定内核的入口点，恶意应用程序可以在跳过参数验证的点进入内核，例如。
2.3 内核组织一个关键的设计问题是操作系统的哪个部分应该在监管模式下运行。
一种可能性是整个操作系统都驻留在内核中，以便所有系统调用的实现都在监管模式下运行。
这种组织被称为单内核。

 In this organization the entire operating system runs with full hardware privilege.
This organi- zation is convenient because the OS designer doesn’t have to decide which part of the operating system doesn’t need full hardware privilege.
Furthermore, it is easier for different parts of the op- erating system to cooperate.
For example, an operating system might have a buffer cache that can be shared both by the ﬁle system and the virtual memory system.
A downside of the monolithic organization is that the interfaces between different parts of the operating system are often complex (as we will see in the rest of this text), and therefore it is easy for an operating system developer to make a mistake.
In a monolithic kernel, a mistake is fatal, because an error in supervisor mode will often cause the kernel to fail.
If the kernel fails, 23 Figure 2.1: A microkernel with a ﬁle-system server the computer stops working, and thus all applications fail too.
The computer must reboot to start again.
在这个组织中，整个操作系统都以完全的硬件特权运行。
这种组织方式很方便，因为操作系统设计者不需要决定哪部分操作系统不需要完全的硬件特权。
此外，不同部分的操作系统更容易合作。
例如，一个操作系统可能有一个可以被文件系统和虚拟内存系统共享的缓冲区缓存。
分散式组织的一个缺点是操作系统不同部分之间的接口通常很复杂（正如我们在本文的其余部分中所看到的），因此操作系统开发人员很容易犯错误。
在分散式内核中，一个错误是致命的，因为在监管模式下的错误通常会导致内核失败。
如果内核失败，计算机就会停止工作，因此所有应用程序也会失败。
计算机必须重新启动才能重新开始。

 To reduce the risk of mistakes in the kernel, OS designers can minimize the amount of operating system code that runs in supervisor mode, and execute the bulk of the operating system in user mode.
This kernel organization is called a microkernel.
Figure 2.1 illustrates this microkernel design.
In the ﬁgure, the ﬁle system runs as a user-level process.
OS services running as processes are called servers.
To allow applications to interact with the ﬁle server, the kernel provides an inter-process communication mechanism to send messages from one user-mode process to another.
For example, if an application like the shell wants to read or write a ﬁle, it sends a message to the ﬁle server and waits for a response.
In a microkernel, the kernel interface consists of a few low-level functions for starting applica- tions, sending messages, accessing device hardware, etc.
This organization allows the kernel to be relatively simple, as most of the operating system resides in user-level servers.
为了减少内核中的错误风险，操作系统设计者可以将在监管模式下运行的操作系统代码的数量最小化，并在用户模式下执行大部分操作系统。
这种内核组织被称为微内核。
图2.1说明了这种微内核设计。
在图中，文件系统作为一个用户级进程运行。
作为进程运行的操作系统服务被称为服务器。
为了允许应用程序与文件服务器进行交互，内核提供了一个进程间通信机制，用于将消息从一个用户模式进程发送到另一个进程。
例如，如果一个像shell这样的应用程序想要读取或写入一个文件，它会发送一个消息给文件服务器并等待响应。
在微内核中，内核接口由一些低级函数组成，用于启动应用程序、发送消息、访问设备硬件等。
这种组织方式使得内核相对简单，因为大部分操作系统都驻留在用户级服务器中。

 Xv6 is implemented as a monolithic kernel, like most Unix operating systems.
Thus, the xv6 kernel interface corresponds to the operating system interface, and the kernel implements the com- plete operating system.
Since xv6 doesn’t provide many services, its kernel is smaller than some microkernels, but conceptually xv6 is monolithic.
2.4 Code: xv6 organization The xv6 kernel source is in the kernel/ sub-directory.
The source is divided into ﬁles, following a rough notion of modularity; Figure 2.2 lists the ﬁles.
The inter-module interfaces are deﬁned in defs.h (kernel/defs.h).
2.5 Process overview The unit of isolation in xv6 (as in other Unix operating systems) is a process.
The process ab- straction prevents one process from wrecking or spying on another process’s memory, CPU, ﬁle descriptors, etc.
It also prevents a process from wrecking the kernel itself, so that a process can’t subvert the kernel’s isolation mechanisms.
Xv6是一个像大多数Unix操作系统一样实现为单内核的操作系统。
因此，xv6内核接口对应于操作系统接口，内核实现了完整的操作系统。
由于xv6没有提供很多服务，所以它的内核比一些微内核要小，但从概念上讲，xv6是单内核的。


2.4 代码：xv6组织
xv6内核源代码位于kernel/子目录中。
源代码被分成了多个文件，遵循了一种大致的模块化概念；图2.2列出了这些文件。
模块间的接口在defs.h（kernel/defs.h）中定义。


2.5 进程概述
在xv6中（就像其他Unix操作系统一样），隔离的单位是进程。
进程抽象防止一个进程破坏或监视另一个进程的内存、CPU、文件描述符等。
它还防止进程破坏内核本身，以便进程无法破坏内核的隔离机制。

 The kernel must implement the process abstraction with care because a buggy or malicious application may trick the kernel or hardware into doing something bad (e.g., circumventing isolation).
The mechanisms used by the kernel to implement 24 MicrokernelshellFile serveruserspacekernelspace Send message File Description Disk block cache for the ﬁle system.
Connect to the user keyboard and screen.
Very ﬁrst boot instructions.
exec() system call.
File descriptor support.
File system.
Physical page allocator.
Handle traps from kernel, and timer interrupts.
File system logging and crash recovery.
Control initialization of other modules during boot.
Pipes.
RISC-V interrupt controller.
Formatted output to the console.
Processes and scheduling.
Locks that yield the CPU.
Locks that don’t yield the CPU.
Early machine-mode boot code.
C string and byte-array library.
Thread switching.
Dispatch system calls to handling function.
File-related system calls.
Process-related system calls.
bio.c console.c entry.S exec.c ﬁle.
内核必须小心地实现进程抽象，因为有缺陷或恶意的应用程序可能会欺骗内核或硬件执行一些不好的操作（例如，规避隔离）。
内核用于实现24个微内核shell文件服务器用户空间内核空间发送消息文件描述磁盘块缓存文件系统。
连接到用户键盘和屏幕。
非常首次引导指令。
exec()系统调用。
文件描述符支持。
文件系统。
物理页面分配器。
处理来自内核的陷阱和定时器中断。
文件系统日志和崩溃恢复。
控制在启动期间初始化其他模块。
管道。
RISC-V中断控制器。
格式化输出到控制台。
进程和调度。
能够让出CPU的锁。
不能让出CPU的锁。
早期机器模式引导代码。
C字符串和字节数组库。
线程切换。
调度系统调用到处理函数。
与文件相关的系统调用。
与进程相关的系统调用。
bio.c console.c entry.S exec.c file.
c fs.c kalloc.c kernelvec.S log.c main.c pipe.c plic.c printf.c proc.c sleeplock.c spinlock.c start.c string.c swtch.S syscall.c sysﬁle.c sysproc.c trampoline.S Assembly code to switch between user and kernel.
trap.c uart.c virtio_disk.c Disk device driver.
vm.c C code to handle and return from traps and interrupts.
Serial-port console device driver.
Manage page tables and address spaces.
Figure 2.2: Xv6 kernel source ﬁles.
processes include the user/supervisor mode ﬂag, address spaces, and time-slicing of threads.
To help enforce isolation, the process abstraction provides the illusion to a program that it has its own private machine.
A process provides a program with what appears to be a private memory system, or address space, which other processes cannot read or write.
A process also provides the program with what appears to be its own CPU to execute the program’s instructions.
Xv6 uses page tables (which are implemented by hardware) to give each process its own ad- dress space.
c fs.c kalloc.c kernelvec.S log.c main.c pipe.c plic.c printf.c proc.c sleeplock.c spinlock.c start.c string.c swtch.S syscall.c sysﬁle.c sysproc.c trampoline.S 用于在用户态和内核态之间切换的汇编代码。
trap.c uart.c virtio_disk.c 磁盘设备驱动程序。
vm.c 用于处理和返回陷阱和中断的C代码。
串口控制台设备驱动程序。
管理页表和地址空间。
图2.2：Xv6内核源文件。
进程包括用户/监管模式标志、地址空间和线程的时间片。
为了帮助实施隔离，进程抽象提供了一个程序的幻觉，即它拥有自己的私有机器。
进程为程序提供了一个看起来像是私有的内存系统或地址空间，其他进程无法读取或写入。
进程还为程序提供了一个看起来是自己的CPU来执行程序的指令。
Xv6使用页表（由硬件实现）为每个进程提供独立的地址空间。

 The RISC-V page table translates (or “maps”) a virtual address (the address that an RISC-V instruction manipulates) to a physical address (an address that the CPU chip sends to main memory).
Xv6 maintains a separate page table for each process that deﬁnes that process’s address space.
As illustrated in Figure 2.3, an address space includes the process’s user memory starting at virtual 25 Figure 2.3: Layout of a process’s virtual address space address zero.
Instructions come ﬁrst, followed by global variables, then the stack, and ﬁnally a “heap” area (for malloc) that the process can expand as needed.
There are a number of factors that limit the maximum size of a process’s address space: pointers on the RISC-V are 64 bits wide; the hardware only uses the low 39 bits when looking up virtual addresses in page tables; and xv6 only uses 38 of those 39 bits.
Thus, the maximum address is 238 − 1 = 0x3fffffffff, which is MAXVA (kernel/riscv.h:348).
RISC-V页面表将虚拟地址（RISC-V指令操作的地址）转换（或“映射”）为物理地址（CPU芯片发送到主存储器的地址）。
Xv6为每个进程维护一个单独的页面表，定义了该进程的地址空间。
如图2.3所示，地址空间包括进程的用户内存，从虚拟地址零开始。
指令首先出现，然后是全局变量，然后是堆栈，最后是一个“堆”区域（用于malloc），进程可以根据需要扩展。
有一些因素限制了进程地址空间的最大大小：RISC-V上的指针宽度为64位；硬件在查找页面表中的虚拟地址时只使用低39位；而xv6只使用其中的38位。
因此，最大地址为238-1 = 0x3fffffffff，即MAXVA（kernel/riscv.h:348）。

 At the top of the address space xv6 reserves a page for a trampoline and a page mapping the process’s trapframe to switch to the kernel, as we will explain in Chapter 4.
The xv6 kernel maintains many pieces of state for each process, which it gathers into a struct proc (kernel/proc.h:86).
A process’s most important pieces of kernel state are its page table, its kernel stack, and its run state.
We’ll use the notation p->xxx to refer to elements of the proc structure; for example, p->pagetable is a pointer to the process’s page table.
Each process has a thread of execution (or thread for short) that executes the process’s instruc- tions.
A thread can be suspended and later resumed.
To switch transparently between processes, the kernel suspends the currently running thread and resumes another process’s thread.
Much of the state of a thread (local variables, function call return addresses) is stored on the thread’s stacks.
Each process has two stacks: a user stack and a kernel stack (p->kstack).
在地址空间的顶部，xv6为一个跳板和一个将进程的陷阱帧映射到内核的页面保留了一个页面，我们将在第4章中解释。
xv6内核为每个进程维护许多状态，它们被收集到一个struct proc（kernel/proc.h:86）中。
进程最重要的内核状态是它的页表、内核栈和运行状态。
我们将使用p->xxx的符号表示proc结构的元素；例如，p->pagetable是指向进程页表的指针。
每个进程都有一个执行线程（或简称为线程），用于执行进程的指令。
线程可以被挂起，稍后恢复。
为了在进程之间透明地切换，内核挂起当前正在运行的线程，并恢复另一个进程的线程。
线程的大部分状态（局部变量、函数调用返回地址）存储在线程的堆栈上。
每个进程有两个堆栈：用户堆栈和内核堆栈（p->kstack）。

 When the process is executing user instructions, only its user stack is in use, and its kernel stack is empty.
When the process enters the kernel (for a system call or interrupt), the kernel code executes on the process’s kernel stack; while a process is in the kernel, its user stack still contains saved data, but isn’t ac- tively used.
A process’s thread alternates between actively using its user stack and its kernel stack.
The kernel stack is separate (and protected from user code) so that the kernel can execute even if a process has wrecked its user stack.
A process can make a system call by executing the RISC-V ecall instruction.
This instruction raises the hardware privilege level and changes the program counter to a kernel-deﬁned entry point.
The code at the entry point switches to a kernel stack and executes the kernel instructions that implement the system call.
当进程执行用户指令时，只使用其用户栈，内核栈为空。
当进程进入内核（进行系统调用或中断）时，内核代码在进程的内核栈上执行；当进程在内核中时，其用户栈仍然包含保存的数据，但不会被主动使用。
进程的线程在用户栈和内核栈之间交替使用。
内核栈是独立的（并且受到用户代码的保护），以便即使进程破坏了其用户栈，内核仍然可以执行。
进程可以通过执行RISC-V ecall指令进行系统调用。
该指令提升硬件特权级别并将程序计数器更改为内核定义的入口点。
入口点处的代码切换到内核栈并执行实现系统调用的内核指令。

 When the system call completes, the kernel switches back to the user 26 0 user textand datauser stackheapMAXVAtrampolinetrapframe stack and returns to user space by calling the sret instruction, which lowers the hardware privilege level and resumes executing user instructions just after the system call instruction.
A process’s thread can “block” in the kernel to wait for I/O, and resume where it left off when the I/O has ﬁnished.
p->state indicates whether the process is allocated, ready to run, running, waiting for I/O, or exiting.
p->pagetable holds the process’s page table, in the format that the RISC-V hardware ex- pects.
xv6 causes the paging hardware to use a process’s p->pagetable when executing that process in user space.
A process’s page table also serves as the record of the addresses of the physical pages allocated to store the process’s memory.
2.6 Code: starting xv6 and the ﬁrst process To make xv6 more concrete, we’ll outline how the kernel starts and runs the ﬁrst process.
当系统调用完成时，内核会切换回用户空间，并通过调用sret指令降低硬件特权级别，继续执行系统调用指令之后的用户指令。
进程的线程可以在内核中“阻塞”以等待I/O，并在I/O完成后从离开的地方继续执行。
p->state表示进程是否已分配、准备运行、正在运行、等待I/O或退出。
p->pagetable保存进程的页表，格式符合RISC-V硬件的期望。
xv6在执行进程的用户空间时，会让分页硬件使用进程的p->pagetable。
进程的页表还充当记录分配给存储进程内存的物理页面地址的记录。
2.6代码：启动xv6和第一个进程为了使xv6更具体，我们将概述内核如何启动和运行第一个进程。

 The subsequent chapters will describe the mechanisms that show up in this overview in more detail.
When the RISC-V computer powers on, it initializes itself and runs a boot loader which is stored in read-only memory.
The boot loader loads the xv6 kernel into memory.
Then, in machine mode, the CPU executes xv6 starting at _entry (kernel/entry.S:6).
The RISC-V starts with paging hardware disabled: virtual addresses map directly to physical addresses.
The loader loads the xv6 kernel into memory at physical address 0x80000000.
The reason it places the kernel at 0x80000000 rather than 0x0 is because the address range 0x0:0x80000000 contains I/O devices.
The instructions at _entry set up a stack so that xv6 can run C code.
Xv6 declares space for an initial stack, stack0, in the ﬁle start.c (kernel/start.c:11).
The code at _entry loads the stack pointer register sp with the address stack0+4096, the top of the stack, because the stack on RISC-V grows down.
后续的章节将更详细地描述在这个概述中出现的机制。
当RISC-V计算机启动时，它会初始化自身并运行存储在只读内存中的引导加载程序。
引导加载程序将xv6内核加载到内存中。
然后，在机器模式下，CPU从_entry（kernel/entry.S:6）开始执行xv6。
RISC-V启动时，分页硬件被禁用：虚拟地址直接映射到物理地址。
加载程序将xv6内核加载到物理地址0x80000000处。
之所以将内核放在0x80000000而不是0x0的原因是因为地址范围0x0:0x80000000包含I/O设备。
_entry处的指令设置了一个堆栈，以便xv6可以运行C代码。
Xv6在文件start.c（kernel/start.c:11）中声明了一个初始堆栈stack0的空间。
_entry处的代码将堆栈指针寄存器sp加载为stack0+4096的地址，即堆栈的顶部，因为RISC-V上的堆栈是向下增长的。

 Now that the kernel has a stack, _entry calls into C code at start (kernel/start.c:21).
The function start performs some conﬁguration that is only allowed in machine mode, and then switches to supervisor mode.
To enter supervisor mode, RISC-V provides the instruction mret.
This instruction is most often used to return from a previous call from supervisor mode to machine mode.
start isn’t returning from such a call, and instead sets things up as if there had been one: it sets the previous privilege mode to supervisor in the register mstatus, it sets the return address to main by writing main’s address into the register mepc, disables virtual address translation in supervisor mode by writing 0 into the page-table register satp, and delegates all interrupts and exceptions to supervisor mode.
Before jumping into supervisor mode, start performs one more task: it programs the clock chip to generate timer interrupts.
With this housekeeping out of the way, start “returns” to super- visor mode by calling mret.
现在内核有了一个栈，_entry在开始时调用C代码（kernel/start.c:21）。
函数start执行一些只允许在机器模式下进行的配置，然后切换到监管者模式。
为了进入监管者模式，RISC-V提供了指令mret。
这个指令通常用于从监管者模式返回到机器模式的前一个调用。
start并不是从这样的调用中返回，而是设置了一些东西，就好像有一个这样的调用：它将先前的特权模式设置为监管者模式，将返回地址设置为main，通过将main的地址写入寄存器mepc，通过将0写入页表寄存器satp，在监管者模式下禁用虚拟地址转换，并将所有中断和异常委托给监管者模式。
在进入监管者模式之前，start还执行了一个任务：它将时钟芯片设置为生成定时器中断。
完成这些杂务后，start通过调用mret“返回”到监管者模式。

 This causes the program counter to change to main (kernel/main.c:11).
After main (kernel/main.c:11) initializes several devices and subsystems, it creates the ﬁrst pro- cess by calling userinit (kernel/proc.c:212).
The ﬁrst process executes a small program written in RISC-V assembly, initcode.S (user/initcode.S:1), which re-enters the kernel by invoking the exec system call.
As we saw in Chapter 1, exec replaces the memory and registers of the current 27 process with a new program (in this case, /init).
Once the kernel has completed exec, it returns to user space in the /init process.
Init (user/init.c:15) creates a new console device ﬁle if needed and then opens it as ﬁle descriptors 0, 1, and 2.
Then it starts a shell on the console.
The system is up.
2.7 Real world In the real world, one can ﬁnd both monolithic kernels and microkernels.
Many Unix kernels are monolithic.
For example, Linux has a monolithic kernel, although some OS functions run as user- level servers (e.g., the windowing system).
这导致程序计数器更改为main（kernel/main.c:11）。
在main（kernel/main.c:11）初始化了几个设备和子系统之后，通过调用userinit（kernel/proc.c:212）创建了第一个进程。
第一个进程执行了一个用RISC-V汇编语言编写的小程序initcode.S（user/initcode.S:1），该程序通过调用exec系统调用重新进入内核。
正如我们在第1章中看到的那样，exec用新程序（在本例中为/init）替换了当前进程的内存和寄存器。
一旦内核完成exec，它就返回到/init进程的用户空间。
Init（user/init.c:15）如果需要会创建一个新的控制台设备文件，然后将其作为文件描述符0、1和2打开。
然后它在控制台上启动一个shell。
系统已启动。
2.7现实世界在现实世界中，可以找到单内核和微内核。
许多Unix内核是单内核的。
例如，Linux有一个单内核，尽管一些操作系统功能作为用户级服务器运行（例如，窗口系统）。

 Kernels such as L4, Minix, and QNX are organized as a microkernel with servers, and have seen wide deployment in embedded settings.
Most operating systems have adopted the process concept, and most processes look similar to xv6’s.
Modern operating systems, however, support several threads within a process, to allow a single process to exploit multiple CPUs.
Supporting multiple threads in a process involves quite a bit of machinery that xv6 doesn’t have, including potential interface changes (e.g., Linux’s clone, a variant of fork), to control which aspects of a process threads share.
2.8 Exercises 1.
You can use gdb to observe the very ﬁrst kernel-to-user transition.
Run make qemu-gdb.
In another window, in the same directory, run gdb.
Type the gdb command break *0x3ffffff10e, which sets a breakpoint at the sret instruction in the kernel that jumps into user space.
Type the continue gdb command.
gdb should stop at the breakpoint, about to execute sret.
Type stepi.
像L4、Minix和QNX这样的内核被组织为带有服务器的微内核，并在嵌入式环境中得到广泛应用。
大多数操作系统都采用了进程的概念，大多数进程看起来与xv6的进程类似。
然而，现代操作系统支持在一个进程内运行多个线程，以允许一个进程利用多个CPU。
支持一个进程中的多个线程涉及到一些xv6没有的机制，包括潜在的接口变化（例如Linux的clone，一种fork的变体），用于控制进程线程共享的方面。
2.8练习1.您可以使用gdb观察第一个内核到用户的转换。
运行make qemu-gdb。
在同一个目录中的另一个窗口中运行gdb。
输入gdb命令break *0x3ffffff10e，在内核中的sret指令处设置断点，该指令跳转到用户空间。
输入continue gdb命令。
gdb应该在断点处停止，即将执行sret。
输入stepi命令。

 gdb should now indicate that it is executing at address 0x0, which is in user space at the start of initcode.S.
28 Chapter 3 Page tables Page tables are the mechanism through which the operating system provides each process with its own private address space and memory.
Page tables determine what memory addresses mean, and what parts of physical memory can be accessed.
They allow xv6 to isolate different process’s ad- dress spaces and to multiplex them onto a single physical memory.
Page tables also provide a level of indirection that allows xv6 to perform a few tricks: mapping the same memory (a trampoline page) in several address spaces, and guarding kernel and user stacks with an unmapped page.
The rest of this chapter explains the page tables that the RISC-V hardware provides and how xv6 uses them.
3.1 Paging hardware As a reminder, RISC-V instructions (both user and kernel) manipulate virtual addresses.
The ma- chine’s RAM, or physical memory, is indexed with physical addresses.
gdb 现在应该指示它正在地址0x0处执行，这是在initcode.S的用户空间的开始处。
第28章页表页表是操作系统提供每个进程独立地址空间和内存的机制。
页表确定内存地址的含义，以及可以访问物理内存的哪些部分。
它们允许xv6隔离不同进程的地址空间，并将它们多路复用到单个物理内存中。
页表还提供了一种间接级别，使xv6能够执行一些技巧：在多个地址空间中映射相同的内存（一个跳板页），并使用未映射的页保护内核和用户堆栈。
本章的其余部分解释了RISC-V硬件提供的页表以及xv6如何使用它们。
3.1分页硬件作为提醒，RISC-V指令（用户和内核）操作虚拟地址。
机器的RAM或物理内存使用物理地址进行索引。

 The RISC-V page table hardware connects these two kinds of addresses, by mapping each virtual address to a physical address.
xv6 runs on Sv39 RISC-V, which means that only the bottom 39 bits of a 64-bit virtual address are used; the top 25 bits are not used.
In this Sv39 conﬁguration, a RISC-V page table is logically an array of 227 (134,217,728) page table entries (PTEs).
Each PTE contains a 44-bit physical page number (PPN) and some ﬂags.
The paging hardware translates a virtual address by using the top 27 bits of the 39 bits to index into the page table to ﬁnd a PTE, and making a 56-bit physical address whose top 44 bits come from the PPN in the PTE and whose bottom 12 bits are copied from the original virtual address.
Figure 3.1 shows this process with a logical view of the page table as a simple array of PTEs (see Figure 3.2 for a fuller story).
A page table gives the operating system control over virtual-to-physical address translations at the granularity of aligned chunks of 4096 (212) bytes.
RISC-V页表硬件通过将每个虚拟地址映射到物理地址来连接这两种地址。
xv6在Sv39 RISC-V上运行，这意味着只使用64位虚拟地址的底部39位；顶部25位未使用。
在这种Sv39配置中，RISC-V页表在逻辑上是一个由227个（134,217,728）页表条目（PTE）组成的数组。
每个PTE包含一个44位的物理页号（PPN）和一些标志。
分页硬件通过使用39位中的前27位作为索引来将虚拟地址转换为物理地址，以查找PTE，并生成一个56位的物理地址，其中前44位来自PTE中的PPN，底部12位从原始虚拟地址复制而来。
图3.1以PTE的简单数组的逻辑视图展示了这个过程（有关更详细的信息，请参见图3.2）。
页表以4096（212）字节对齐的块的粒度，使操作系统能够控制虚拟地址到物理地址的转换。

 Such a chunk is called a page.
In Sv39 RISC-V, the top 25 bits of a virtual address are not used for translation; in the future, RISC-V may use those bits to deﬁne more levels of translation.
The physical address also has room for growth: there is room in the PTE format for the physical page number to grow by another 10 bits.
29 Figure 3.1: RISC-V virtual and physical addresses, with a simpliﬁed logical page table.
As Figure 3.2 shows, the actual translation happens in three steps.
A page table is stored in physical memory as a three-level tree.
The root of the tree is a 4096-byte page-table page that contains 512 PTEs, which contain the physical addresses for page-table pages in the next level of the tree.
Each of those pages contains 512 PTEs for the ﬁnal level in the tree.
The paging hardware uses the top 9 bits of the 27 bits to select a PTE in the root page-table page, the middle 9 bits to select a PTE in a page-table page in the next level of the tree, and the bottom 9 bits to select the ﬁnal PTE.
这样的块被称为页面。
在Sv39 RISC-V中，虚拟地址的前25位不用于翻译；在未来，RISC-V可能会使用这些位来定义更多的翻译级别。
物理地址也有增长的空间：PTE格式中的物理页号还可以增加10位。
图3.1：RISC-V虚拟地址和物理地址，带有简化的逻辑页表。
如图3.2所示，实际的翻译分为三个步骤。
页表以三级树的形式存储在物理内存中。
树的根是一个4096字节的页表页，其中包含512个PTE，这些PTE包含下一级树中页表页的物理地址。
每个页包含512个PTE，用于树中的最后一级。
分页硬件使用27位中的前9位来选择根页表页中的PTE，中间的9位来选择树中下一级的页表页中的PTE，底部的9位来选择最后的PTE。

 If any of the three PTEs required to translate an address is not present, the paging hardware raises a page-fault exception, leaving it up to the kernel to handle the exception (see Chapter 4).
This three-level structure allows a page table to omit entire page table pages in the common case in which large ranges of virtual addresses have no mappings.
Each PTE contains ﬂag bits that tell the paging hardware how the associated virtual address is allowed to be used.
PTE_V indicates whether the PTE is present: if it is not set, a reference to the page causes an exception (i.e.
is not allowed).
PTE_R controls whether instructions are allowed to read to the page.
PTE_W controls whether instructions are allowed to write to the page.
PTE_X controls whether the CPU may interpret the content of the page as instructions and execute them.
PTE_U controls whether instructions in user mode are allowed to access the page; if PTE_U is not set, the PTE can be used only in supervisor mode.
Figure 3.2 shows how it all works.
如果用于翻译地址的三个PTE之一不存在，分页硬件会引发页面错误异常，由内核处理该异常（参见第4章）。
这种三级结构允许页表在常见情况下省略整个页表页，即大范围的虚拟地址没有映射。
每个PTE包含标志位，告诉分页硬件如何使用相关的虚拟地址。
PTE_V指示PTE是否存在：如果未设置，对页面的引用会引发异常（即不允许）。
PTE_R控制是否允许指令读取页面。
PTE_W控制是否允许指令写入页面。
PTE_X控制CPU是否可以将页面内容解释为指令并执行它们。
PTE_U控制是否允许用户模式下的指令访问页面；如果未设置PTE_U，则PTE只能在特权模式下使用。
图3.2展示了它的工作原理。

 The ﬂags and all other page hardware-related structures are deﬁned in (kernel/riscv.h) To tell the hardware to use a page table, the kernel must write the physical address of the root page-table page into the satp register.
Each CPU has its own satp.
A CPU will translate all addresses generated by subsequent instructions using the page table pointed to by its own satp.
Each CPU has its own satp so that different CPUs can run different processes, each with a private address space described by its own page table.
A few notes about terms.
Physical memory refers to storage cells in DRAM.
A byte of physical memory has an address, called a physical address.
ﬂags和其他与页面硬件相关的结构在（kernel/riscv.h）中定义。
为了告诉硬件使用页表，内核必须将根页表页的物理地址写入satp寄存器。
每个CPU都有自己的satp。
CPU将使用由其自己的satp指向的页表来翻译后续指令生成的所有地址。
每个CPU都有自己的satp，以便不同的CPU可以运行不同的进程，每个进程都有由其自己的页表描述的私有地址空间。
关于术语的一些说明。
物理内存指的是DRAM中的存储单元。
物理内存的每个字节都有一个称为物理地址的地址。

